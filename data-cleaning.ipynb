{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from random_word import Wordnik\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to scrape prompts from Lexica API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_strings(num_items: int, counter: int):\n",
    "    '''generate random words as search strings for lexica'''    \n",
    "    batch_size = 10\n",
    "    num_calls = math.ceil(num_items/batch_size)\n",
    "    output = []\n",
    "    wordnik_service = Wordnik()\n",
    "    for i in range(num_calls):\n",
    "        try:\n",
    "            # Return a single random word\n",
    "            res = wordnik_service.get_random_words(includePartOfSpeech =\"noun,verb,adverb\",hasDictionaryDef=True, limit=batch_size)\n",
    "            #TODO: Check if adding a duplicate search term\n",
    "            [output.append(x) for x in res]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    print('Generated ', int(batch_size * num_calls), ' search terms.' )\n",
    "    return output\n",
    "\n",
    "def lexica_search(terms: list, counter: int):\n",
    "    '''search and store lexica results via their locked-down and rate-limited api'''\n",
    "    search_base='https://lexica.art/api/v1/search?q='\n",
    "    prompts = pd.DataFrame(columns=['search_string','source','prompt'])\n",
    "    print('Starting counter is: ', counter)\n",
    "    for i in range(counter,len(terms)):\n",
    "        #print('Searching term: ' , item)\n",
    "        query = terms[i]\n",
    "        query = query.replace(' ', '+')\n",
    "        try:\n",
    "            d = requests.get(url=(search_base + query))\n",
    "            data = d.json()\n",
    "            obj = data['images']\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Writing counter to file: ', counter)\n",
    "            time.sleep(35)\n",
    "            f = open('./counter.txt', 'w')\n",
    "            f.write(str(counter))\n",
    "            f.close()\n",
    "            return prompts, counter\n",
    "        #print('Adding items to db for search term: ', item)\n",
    "        for item in obj:\n",
    "            row = [query, item['src'], item['prompt']]\n",
    "            prompts.loc[item['id']] = row\n",
    "        counter +=1\n",
    "        print('Commited prompts for term ', counter, ' out of ', len(terms))\n",
    "        time.sleep(.5)\n",
    "    f = open('./counter.txt', 'w')\n",
    "    f.write(counter)\n",
    "    f.close()\n",
    "    return prompts, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a database of prompts for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./1000-most-common.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    common = [line.rstrip() for line in lines]\n",
    "with open('./counter.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    counter = int(lines[0])\n",
    "\n",
    "while counter != (len(common)-1):\n",
    "    print(\"Starting the procedure again with counter: \", counter)\n",
    "    res_common, counter = lexica_search(terms = common, counter = counter)\n",
    "    filename = './prompts-with-common-' + str(counter) + '.json'\n",
    "    res_common.to_json(filename, orient='split')\n",
    "\n",
    "\n",
    "#res.to_json('./common-df.json',orient='split')\n",
    "res = pd.read_json('./common-df.json', orient='split')\n",
    "master = pd.read_json('./master-prompts.json', orient='split')\n",
    "\n",
    "full = pd.concat([master,res])\n",
    "full.shape\n",
    "full.to_csv('./full-prompts.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing prompts w/spacy\n",
    "full = pd.read_json('./full-prompts.json', orient='split')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def tokenize(prompt):\n",
    "    temp = []\n",
    "    f = nlp(prompt)\n",
    "    for ent in f.ents:\n",
    "        temp.append({'token': ent.text,'char_start': ent.start_char, 'char_end': ent.end_char, 'label': None, 'is_weak_label': False, 'pos': ent.label_})\n",
    "    return temp\n",
    "\n",
    "full['tokens'] = full['prompt'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Annotations\n",
    "\n",
    "For experimentation purposes, I used the community version of Label Studio to annotate ~230 prompts. The label schema is [ARTIST, OTHER]. Label studio ground truth needs to be transformed to a spacy-compatible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding GT for the prompts based off of labels from Label Studio\n",
    "import json\n",
    "f = open('./gt.json')\n",
    "gt_file = json.load(f)\n",
    "#print('Example entry: ', gt_file[58])\n",
    "\n",
    "filtered = []\n",
    "for x in gt_file:\n",
    "    filtered.append({'annotations': x['annotations'][0]['result'],'data': x['data']})\n",
    "#print(filtered[58])\n",
    "\n",
    "full['gt_raw'] = None\n",
    "for i in range(full.shape[0]):\n",
    "    ss = full.index[i]\n",
    "    for item in filtered:\n",
    "        if item['data']['Unnamed: 0'] == ss:\n",
    "            #print('found annoation match')\n",
    "            #print('df row: ', full.loc[ss])\n",
    "            #print('annotations row: ', item)\n",
    "            full['gt_raw'][i] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 168, 'end': 192, 'text': 'cornelis van poelenburgh', 'labels': ['Artist']}\n",
      "{'start': 197, 'end': 208, 'text': 'dosso dossi', 'labels': ['Artist']}\n",
      "{'start': 114, 'end': 128, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 139, 'end': 152, 'text': 'craig mullins', 'labels': ['Artist']}\n",
      "{'start': 20, 'end': 30, 'text': 'Zaha Hadid', 'labels': ['Artist']}\n",
      "{'start': 172, 'end': 176, 'text': 'WLOP', 'labels': ['Artist']}\n",
      "{'start': 181, 'end': 188, 'text': 'Artgerm', 'labels': ['Artist']}\n",
      "{'start': 193, 'end': 207, 'text': 'Greg Rutkowski', 'labels': ['Artist']}\n",
      "{'start': 212, 'end': 226, 'text': 'Alphonse Mucha', 'labels': ['Artist']}\n",
      "{'start': 107, 'end': 119, 'text': 'mark coleran', 'labels': ['Artist']}\n",
      "{'start': 123, 'end': 135, 'text': 'jayse hansen', 'labels': ['Artist']}\n",
      "{'start': 58, 'end': 65, 'text': 'Artgerm', 'labels': ['Artist']}\n",
      "{'start': 70, 'end': 85, 'text': 'Charlie Bowater', 'labels': ['Artist']}\n",
      "{'start': 90, 'end': 102, 'text': 'Atey Ghailan', 'labels': ['Artist']}\n",
      "{'start': 107, 'end': 119, 'text': 'Mike Mignola', 'labels': ['Artist']}\n",
      "{'start': 248, 'end': 257, 'text': 'alex grey', 'labels': ['Artist']}\n",
      "{'start': 262, 'end': 274, 'text': 'gustave dore', 'labels': ['Artist']}\n",
      "{'start': 226, 'end': 240, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 245, 'end': 259, 'text': 'alphonse mucha', 'labels': ['Artist']}\n",
      "{'start': 147, 'end': 156, 'text': 'Ruan Jia ', 'labels': ['Artist']}\n",
      "{'start': 160, 'end': 167, 'text': 'Artgerm', 'labels': ['Artist']}\n",
      "{'start': 172, 'end': 184, 'text': 'Range Murata', 'labels': ['Artist']}\n",
      "{'start': 198, 'end': 207, 'text': 'Ross Tran', 'labels': ['Artist']}\n",
      "{'start': 212, 'end': 239, 'text': 'William-Adolphe Bouguereau ', 'labels': ['Artist']}\n",
      "{'start': 243, 'end': 249, 'text': 'Beeple', 'labels': ['Artist']}\n",
      "{'start': 189, 'end': 193, 'text': 'WLOP', 'labels': ['Artist']}\n",
      "{'start': 326, 'end': 340, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 345, 'end': 359, 'text': 'alphonse mucha', 'labels': ['Artist']}\n",
      "{'start': 150, 'end': 161, 'text': 'kim jung gi', 'labels': ['Artist']}\n",
      "{'start': 163, 'end': 177, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 182, 'end': 197, 'text': 'francis bacon, ', 'labels': ['Artist']}\n",
      "{'start': 11, 'end': 26, 'text': 'charlie bowater', 'labels': ['Artist']}\n",
      "{'start': 42, 'end': 49, 'text': 'artgerm', 'labels': ['Artist']}\n",
      "{'start': 115, 'end': 122, 'text': 'bowater', 'labels': ['Artist']}\n",
      "{'start': 124, 'end': 131, 'text': 'charlie', 'labels': ['Artist']}\n",
      "{'start': 38, 'end': 47, 'text': 'junji ito', 'labels': ['Artist']}\n",
      "{'start': 260, 'end': 274, 'text': ' tristan eaton', 'labels': ['Artist']}\n",
      "{'start': 276, 'end': 286, 'text': 'victo ngai', 'labels': ['Artist']}\n",
      "{'start': 289, 'end': 305, 'text': 'maxfield parrish', 'labels': ['Artist']}\n",
      "{'start': 316, 'end': 321, 'text': 'ryden', 'labels': ['Artist']}\n",
      "{'start': 107, 'end': 123, 'text': 'vittorio de sica', 'labels': ['Artist']}\n",
      "{'start': 0, 'end': 10, 'text': 'Il Gabibbo', 'labels': ['Artist']}\n",
      "{'start': 260, 'end': 279, 'text': 'johannes wessermark', 'labels': ['Artist']}\n",
      "{'start': 248, 'end': 255, 'text': 'artgerm', 'labels': ['Artist']}\n",
      "{'start': 234, 'end': 243, 'text': 'marc hill', 'labels': ['Artist']}\n",
      "{'start': 11, 'end': 28, 'text': 'William Eggleston', 'labels': ['Artist']}\n",
      "{'start': 55, 'end': 61, 'text': 'beeple', 'labels': ['Artist']}\n",
      "{'start': 63, 'end': 72, 'text': 'cgsociety', 'labels': ['Artist']}\n",
      "{'start': 125, 'end': 138, 'text': 'wayne barlowe', 'labels': ['Artist']}\n",
      "{'start': 143, 'end': 156, 'text': 'francis bacon', 'labels': ['Artist']}\n",
      "{'start': 161, 'end': 168, 'text': 'artgerm', 'labels': ['Artist']}\n",
      "{'start': 173, 'end': 177, 'text': 'wlop', 'labels': ['Artist']}\n",
      "{'start': 35, 'end': 47, 'text': 'John Everett', 'labels': ['Artist']}\n",
      "{'start': 48, 'end': 55, 'text': 'Millais', 'labels': ['Artist']}\n",
      "{'start': 60, 'end': 83, 'text': 'Dante Gabriel Rossetti ', 'labels': ['Artist']}\n",
      "{'start': 87, 'end': 99, 'text': 'John Collier', 'labels': ['Artist']}\n",
      "{'start': 104, 'end': 127, 'text': 'john william waterhouse', 'labels': ['Artist']}\n",
      "{'start': 70, 'end': 88, 'text': 'genndy tartakovsky', 'labels': ['Artist']}\n",
      "{'start': 28, 'end': 35, 'text': 'Dan May', 'labels': ['Artist']}\n",
      "{'start': 51, 'end': 64, 'text': 'kentaro miura', 'labels': ['Artist']}\n",
      "{'start': 68, 'end': 80, 'text': ' kim jung gi', 'labels': ['Artist']}\n",
      "{'start': 17, 'end': 31, 'text': 'nicolas delort', 'labels': ['Artist']}\n",
      "{'start': 51, 'end': 65, 'text': 'ilya kuvshinov', 'labels': ['Artist']}\n",
      "{'start': 96, 'end': 103, 'text': 'balthus', 'labels': ['Artist']}\n",
      "{'start': 17, 'end': 31, 'text': 'nicolas delort', 'labels': ['Artist']}\n",
      "{'start': 33, 'end': 40, 'text': 'moebius', 'labels': ['Artist']}\n",
      "{'start': 42, 'end': 52, 'text': 'victo ngai', 'labels': ['Artist']}\n",
      "{'start': 54, 'end': 68, 'text': 'josan gonzalez', 'labels': ['Artist']}\n",
      "{'start': 70, 'end': 80, 'text': 'kilian eng', 'labels': ['Artist']}\n",
      "{'start': 39, 'end': 53, 'text': 'Francisco Goya', 'labels': ['Artist']}\n",
      "{'start': 177, 'end': 189, 'text': 'ayami kojima', 'labels': ['Artist']}\n",
      "{'start': 191, 'end': 207, 'text': 'greg hildebrandt', 'labels': ['Artist']}\n",
      "{'start': 209, 'end': 219, 'text': 'mark ryden', 'labels': ['Artist']}\n",
      "{'start': 322, 'end': 335, 'text': 'jenny saville', 'labels': ['Artist']}\n",
      "{'start': 132, 'end': 145, 'text': 'ayami kojima,', 'labels': ['Artist']}\n",
      "{'start': 146, 'end': 162, 'text': 'greg hildebrandt', 'labels': ['Artist']}\n",
      "{'start': 164, 'end': 174, 'text': 'mark ryden', 'labels': ['Artist']}\n",
      "{'start': 225, 'end': 235, 'text': 'james jean', 'labels': ['Artist']}\n",
      "{'start': 240, 'end': 253, 'text': 'jenny saville', 'labels': ['Artist']}\n",
      "{'start': 95, 'end': 109, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 111, 'end': 128, 'text': 'magali villeneuve', 'labels': ['Artist']}\n",
      "{'start': 139, 'end': 152, 'text': 'jeremy lipkin', 'labels': ['Artist']}\n",
      "{'start': 157, 'end': 172, 'text': 'michael garmash', 'labels': ['Artist']}\n",
      "{'start': 176, 'end': 184, 'text': ' rob rey', 'labels': ['Artist']}\n",
      "{'start': 0, 'end': 14, 'text': 'Ricardo Bofill', 'labels': ['Artist']}\n",
      "{'start': 130, 'end': 150, 'text': 'Gertrude Abercrombie', 'labels': ['Artist']}\n",
      "{'start': 152, 'end': 158, 'text': 'Beeple', 'labels': ['Artist']}\n",
      "{'start': 431, 'end': 438, 'text': 'artgerm', 'labels': ['Artist']}\n",
      "{'start': 247, 'end': 261, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 266, 'end': 280, 'text': 'alphonse mucha', 'labels': ['Artist']}\n",
      "{'start': 107, 'end': 113, 'text': 'ghibli', 'labels': ['Artist']}\n",
      "{'start': 164, 'end': 179, 'text': 'Joaquin Sorolla', 'labels': ['Artist']}\n",
      "{'start': 180, 'end': 197, 'text': 'rhads Leyendecker', 'labels': ['Artist']}\n",
      "{'start': 202, 'end': 213, 'text': 'Ohara Koson', 'labels': ['Artist']}\n",
      "{'start': 218, 'end': 232, 'text': 'Thomas Kinkade', 'labels': ['Artist']}\n",
      "{'start': 92, 'end': 103, 'text': 'Ryoji Ikeda', 'labels': ['Artist']}\n",
      "{'start': 105, 'end': 121, 'text': 'Johannes Vermeer', 'labels': ['Artist']}\n",
      "{'start': 123, 'end': 136, 'text': 'Rene Magritte', 'labels': ['Artist']}\n",
      "{'start': 138, 'end': 151, 'text': 'Francis Bacon', 'labels': ['Artist']}\n",
      "{'start': 115, 'end': 124, 'text': 'cgsociety', 'labels': ['Artist']}\n",
      "{'start': 126, 'end': 141, 'text': 'Ralph McQuarrie', 'labels': ['Artist']}\n",
      "{'start': 146, 'end': 160, 'text': 'Greg Rutkowski', 'labels': ['Artist']}\n",
      "{'start': 107, 'end': 123, 'text': 'vittorio de sica', 'labels': ['Artist']}\n",
      "{'start': 0, 'end': 10, 'text': 'Il Gabibbo', 'labels': ['Artist']}\n",
      "{'start': 128, 'end': 134, 'text': 'beeple', 'labels': ['Artist']}\n",
      "{'start': 97, 'end': 112, 'text': 'anato finnstark', 'labels': ['Artist']}\n",
      "{'start': 82, 'end': 92, 'text': 'joe fenton', 'labels': ['Artist']}\n",
      "{'start': 164, 'end': 178, 'text': 'lisa yuskavage', 'labels': ['Artist']}\n",
      "{'start': 148, 'end': 159, 'text': 'steve hanks', 'labels': ['Artist']}\n",
      "{'start': 164, 'end': 178, 'text': 'lisa yuskavage', 'labels': ['Artist']}\n",
      "{'start': 148, 'end': 159, 'text': 'steve hanks', 'labels': ['Artist']}\n",
      "{'start': 183, 'end': 197, 'text': 'serov valentin', 'labels': ['Artist']}\n",
      "{'start': 202, 'end': 211, 'text': 'tarkovsky', 'labels': ['Artist']}\n",
      "{'start': 119, 'end': 127, 'text': 'Zurbaran', 'labels': ['Artist']}\n",
      "{'start': 129, 'end': 142, 'text': 'Rene Magritte', 'labels': ['Artist']}\n",
      "{'start': 144, 'end': 157, 'text': 'Jean Delville', 'labels': ['Artist']}\n",
      "{'start': 159, 'end': 168, 'text': 'Max Ernst', 'labels': ['Artist']}\n",
      "{'start': 170, 'end': 190, 'text': 'Maria Sybilla Merian', 'labels': ['Artist']}\n",
      "{'start': 233, 'end': 243, 'text': 'james jean', 'labels': ['Artist']}\n",
      "{'start': 245, 'end': 254, 'text': 'okuda sam', 'labels': ['Artist']}\n",
      "{'start': 255, 'end': 261, 'text': 'miguel', 'labels': ['Artist']}\n",
      "{'start': 263, 'end': 276, 'text': 'android jones', 'labels': ['Artist']}\n",
      "{'start': 278, 'end': 284, 'text': 'beeple', 'labels': ['Artist']}\n",
      "{'start': 286, 'end': 291, 'text': 'rhads', 'labels': ['Artist']}\n",
      "{'start': 293, 'end': 307, 'text': 'alphonse mucha', 'labels': ['Artist']}\n",
      "{'start': 246, 'end': 257, 'text': 'kay nielsen', 'labels': ['Artist']}\n",
      "{'start': 262, 'end': 271, 'text': 'zeen chin', 'labels': ['Artist']}\n",
      "{'start': 276, 'end': 288, 'text': 'wadim kashin', 'labels': ['Artist']}\n",
      "{'start': 294, 'end': 306, 'text': 'angyeob park', 'labels': ['Artist']}\n",
      "{'start': 308, 'end': 322, 'text': 'terada katsuya', 'labels': ['Artist']}\n",
      "{'start': 11, 'end': 24, 'text': ' paolo panini', 'labels': ['Artist']}\n",
      "{'start': 72, 'end': 85, 'text': 'klein bottley', 'labels': ['Artist']}\n",
      "{'start': 342, 'end': 358, 'text': 'Denis Villeneuve', 'labels': ['Artist']}\n",
      "{'start': 360, 'end': 367, 'text': 'Lubezki', 'labels': ['Artist']}\n",
      "{'start': 369, 'end': 379, 'text': 'Gaspar Noe', 'labels': ['Artist']}\n",
      "{'start': 381, 'end': 398, 'text': 'Christopher Doyle', 'labels': ['Artist']}\n",
      "{'start': 403, 'end': 423, 'text': 'Alejandro Jodorowsky', 'labels': ['Artist']}\n",
      "{'start': 70, 'end': 88, 'text': 'genndy tartakovsky', 'labels': ['Artist']}\n",
      "{'start': 306, 'end': 313, 'text': 'Artgerm', 'labels': ['Artist']}\n",
      "{'start': 318, 'end': 332, 'text': 'Greg Rutkowski', 'labels': ['Artist']}\n",
      "{'start': 337, 'end': 351, 'text': 'Alphonse Mucha', 'labels': ['Artist']}\n",
      "{'start': 11, 'end': 28, 'text': 'William Eggleston', 'labels': ['Artist']}\n",
      "{'start': 62, 'end': 76, 'text': 'frank frazetta', 'labels': ['Artist']}\n",
      "{'start': 97, 'end': 111, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 116, 'end': 130, 'text': 'alphonse mucha', 'labels': ['Artist']}\n",
      "{'start': 80, 'end': 92, 'text': ' jean giraud', 'labels': ['Artist']}\n",
      "{'start': 201, 'end': 205, 'text': 'wlop', 'labels': ['Artist']}\n",
      "{'start': 207, 'end': 212, 'text': 'wenjr', 'labels': ['Artist']}\n",
      "{'start': 214, 'end': 220, 'text': 'beeple', 'labels': ['Artist']}\n",
      "{'start': 187, 'end': 194, 'text': 'Artgerm', 'labels': ['Artist']}\n",
      "{'start': 199, 'end': 213, 'text': 'Greg Rutkowski', 'labels': ['Artist']}\n",
      "{'start': 218, 'end': 232, 'text': 'Alphonse Mucha', 'labels': ['Artist']}\n",
      "{'start': 437, 'end': 443, 'text': 'beeple', 'labels': ['Artist']}\n",
      "{'start': 444, 'end': 455, 'text': 'Anton Pieck', 'labels': ['Artist']}\n",
      "{'start': 457, 'end': 469, 'text': 'ean Delville', 'labels': ['Artist']}\n",
      "{'start': 471, 'end': 476, 'text': 'Amano', 'labels': ['Artist']}\n",
      "{'start': 477, 'end': 488, 'text': 'Yves Tanguy', 'labels': ['Artist']}\n",
      "{'start': 490, 'end': 504, 'text': 'Alphonse Mucha', 'labels': ['Artist']}\n",
      "{'start': 506, 'end': 519, 'text': 'Ernst Haeckel', 'labels': ['Artist']}\n",
      "{'start': 521, 'end': 541, 'text': 'Edward Robert Hughes', 'labels': ['Artist']}\n",
      "{'start': 542, 'end': 561, 'text': 'Stanisław Szukalski', 'labels': ['Artist']}\n",
      "{'start': 2, 'end': 17, 'text': 'norman rockwell', 'labels': ['Artist']}\n",
      "{'start': 16, 'end': 25, 'text': 'mc escher', 'labels': ['Artist']}\n",
      "{'start': 27, 'end': 38, 'text': 'M.C. Escher', 'labels': ['Artist']}\n",
      "{'start': 31, 'end': 39, 'text': 'ruan jia', 'labels': ['Artist']}\n",
      "{'start': 44, 'end': 52, 'text': 'yun ling', 'labels': ['Artist']}\n",
      "{'start': 104, 'end': 118, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 120, 'end': 125, 'text': 'loish', 'labels': ['Artist']}\n",
      "{'start': 134, 'end': 148, 'text': 'ferdinand knab', 'labels': ['Artist']}\n",
      "{'start': 150, 'end': 163, 'text': 'makoto shinka', 'labels': ['Artist']}\n",
      "{'start': 169, 'end': 184, 'text': 'lois van baarle', 'labels': ['Artist']}\n",
      "{'start': 186, 'end': 200, 'text': 'ilya kuvshinov', 'labels': ['Artist']}\n",
      "{'start': 202, 'end': 211, 'text': 'rossdraws', 'labels': ['Artist']}\n",
      "{'start': 213, 'end': 224, 'text': 'tom bagshaw', 'labels': ['Artist']}\n",
      "{'start': 12, 'end': 26, 'text': 'huang gongwang', 'labels': ['Artist']}\n",
      "{'start': 18, 'end': 32, 'text': 'tetsuya nomura', 'labels': ['Artist']}\n",
      "{'start': 16, 'end': 25, 'text': 'mc escher', 'labels': ['Artist']}\n",
      "{'start': 72, 'end': 85, 'text': 'klein bottley', 'labels': ['Artist']}\n",
      "{'start': 246, 'end': 257, 'text': 'kay nielsen', 'labels': ['Artist']}\n",
      "{'start': 262, 'end': 271, 'text': 'zeen chin', 'labels': ['Artist']}\n",
      "{'start': 276, 'end': 288, 'text': 'wadim kashin', 'labels': ['Artist']}\n",
      "{'start': 294, 'end': 306, 'text': 'angyeob park', 'labels': ['Artist']}\n",
      "{'start': 308, 'end': 322, 'text': 'terada katsuya', 'labels': ['Artist']}\n",
      "{'start': 76, 'end': 89, 'text': 'tristan eaton', 'labels': ['Artist']}\n",
      "{'start': 91, 'end': 106, 'text': 'stanley artgerm', 'labels': ['Artist']}\n",
      "{'start': 108, 'end': 119, 'text': 'tom bagshaw', 'labels': ['Artist']}\n",
      "{'start': 121, 'end': 135, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 137, 'end': 152, 'text': 'carne griffiths', 'labels': ['Artist']}\n",
      "{'start': 154, 'end': 166, 'text': 'ayami kojima', 'labels': ['Artist']}\n",
      "{'start': 168, 'end': 177, 'text': 'beksinski', 'labels': ['Artist']}\n",
      "{'start': 179, 'end': 184, 'text': 'giger', 'labels': ['Artist']}\n",
      "{'start': 201, 'end': 205, 'text': 'wlop', 'labels': ['Artist']}\n",
      "{'start': 207, 'end': 212, 'text': 'wenjr', 'labels': ['Artist']}\n",
      "{'start': 214, 'end': 220, 'text': 'beeple', 'labels': ['Artist']}\n",
      "{'start': 104, 'end': 115, 'text': 'cory loftis', 'labels': ['Artist']}\n",
      "{'start': 117, 'end': 130, 'text': 'fenghua zhong', 'labels': ['Artist']}\n",
      "{'start': 145, 'end': 160, 'text': 'ismail inceoglu', 'labels': ['Artist']}\n",
      "{'start': 80, 'end': 92, 'text': ' jean giraud', 'labels': ['Artist']}\n",
      "{'start': 59, 'end': 72, 'text': 'edward hopper', 'labels': ['Artist']}\n",
      "{'start': 93, 'end': 112, 'text': 'zdzislaw beksisnski', 'labels': ['Artist']}\n",
      "{'start': 77, 'end': 91, 'text': 'james gilleard', 'labels': ['Artist']}\n",
      "{'start': 13, 'end': 19, 'text': 'Yoyaan', 'labels': ['Artist']}\n",
      "{'start': 71, 'end': 83, 'text': 'eyvind earle', 'labels': ['Artist']}\n",
      "{'start': 56, 'end': 66, 'text': 'dan flavin', 'labels': ['Artist']}\n",
      "{'start': 110, 'end': 121, 'text': 'matt murphy', 'labels': ['Artist']}\n",
      "{'start': 123, 'end': 133, 'text': 'enes dirig', 'labels': ['Artist']}\n",
      "{'start': 135, 'end': 148, 'text': 'jeremy enecio', 'labels': ['Artist']}\n",
      "{'start': 161, 'end': 175, 'text': 'miles johnston', 'labels': ['Artist']}\n",
      "{'start': 177, 'end': 182, 'text': 'monet', 'labels': ['Artist']}\n",
      "{'start': 201, 'end': 221, 'text': 'john william godward', 'labels': ['Artist']}\n",
      "{'start': 234, 'end': 249, 'text': 'yoshitaka amano', 'labels': ['Artist']}\n",
      "{'start': 251, 'end': 265, 'text': 'miles johnston', 'labels': ['Artist']}\n",
      "{'start': 267, 'end': 279, 'text': 'louise zhang', 'labels': ['Artist']}\n",
      "{'start': 281, 'end': 292, 'text': 'matt murphy', 'labels': ['Artist']}\n",
      "{'start': 294, 'end': 304, 'text': 'enes dirig', 'labels': ['Artist']}\n",
      "{'start': 306, 'end': 319, 'text': 'pekka halonen', 'labels': ['Artist']}\n",
      "{'start': 167, 'end': 171, 'text': 'wlop', 'labels': ['Artist']}\n",
      "{'start': 195, 'end': 209, 'text': 'makoto shinkai', 'labels': ['Artist']}\n",
      "{'start': 214, 'end': 227, 'text': 'studio ghibli', 'labels': ['Artist']}\n",
      "{'start': 126, 'end': 130, 'text': 'wlop', 'labels': ['Artist']}\n",
      "{'start': 135, 'end': 149, 'text': 'greg rutkowski', 'labels': ['Artist']}\n",
      "{'start': 154, 'end': 169, 'text': 'makoto shinkai ', 'labels': ['Artist']}\n",
      "{'start': 173, 'end': 186, 'text': 'studio ghibli', 'labels': ['Artist']}\n",
      "{'start': 85, 'end': 99, 'text': 'makoto shinkai', 'labels': ['Artist']}\n",
      "{'start': 101, 'end': 107, 'text': 'ghibli', 'labels': ['Artist']}\n",
      "{'start': 32, 'end': 47, 'text': 'annie leibovitz', 'labels': ['Artist']}\n",
      "{'start': 52, 'end': 65, 'text': 'steve mccurry', 'labels': ['Artist']}\n",
      "{'start': 70, 'end': 83, 'text': 'kentaro miura', 'labels': ['Artist']}\n",
      "{'start': 27, 'end': 41, 'text': 'marcel duchamp', 'labels': ['Artist']}\n",
      "{'start': 80, 'end': 94, 'text': 'marcel duchamp', 'labels': ['Artist']}\n",
      "{'start': 96, 'end': 103, 'text': 'man ray', 'labels': ['Artist']}\n",
      "{'start': 105, 'end': 116, 'text': 'hito steyer', 'labels': ['Artist']}\n",
      "{'start': 119, 'end': 131, 'text': 'saadane afif', 'labels': ['Artist']}\n",
      "{'start': 122, 'end': 137, 'text': 'lois van baarle', 'labels': ['Artist']}\n",
      "{'start': 139, 'end': 153, 'text': 'ilya kuvshinov', 'labels': ['Artist']}\n",
      "{'start': 155, 'end': 164, 'text': 'rossdraws', 'labels': ['Artist']}\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(df.shape[0]):\n",
    "    if df['gt_raw'][i] is not None:\n",
    "        for item in df['gt_raw'][i]['annotations']:\n",
    "            print(item['value'])\n",
    "\n",
    "trim = df[df['gt_raw'].notnull()]\n",
    "trim.shape\n",
    "trim.to_json('./trim-df.json', orient='split')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Labeling with BART Large MNLI\n",
    "\n",
    "Weak supervision is a helpful technique when working with few or no labeled examples. Here, I demonstrate using BART LLM as a source of weak signal for labeling. For each entity that has a \"PERSON\" part-of-speech tag from spacy, ask BART whether this person is an artist or not. If prob(Yes) > 0.85, weakly label example as ARTIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'token': 'james jean', 'char_start': 162, 'char_end': 172, 'label': 'artist', 'is_weak_label': True, 'pos': 'PERSON'}]\n"
     ]
    }
   ],
   "source": [
    "temp = full.iloc[222]['tokens']\n",
    "print(temp)\n",
    "labels = ['artist', 'other']\n",
    "threshold = 0.80\n",
    "for item in temp:\n",
    "    if item['label'] is None and item['pos'] == 'PERSON':\n",
    "        res = classifier(item['token'], labels)\n",
    "        print(res['sequence'],' : ', res['scores'][0])\n",
    "        if (res['scores'][0] > threshold):\n",
    "            item['label'] = 'artist'\n",
    "            item['is_weak_label'] = True\n",
    "            #print(item)\n",
    "            annotation = annotation['annotations'].append(item)\n",
    "\n",
    "#Omitting adding these weak labels to the training set for now, since the model was able to get strong scores to start.\n",
    "'''for i in range(full.shape[0]):\n",
    "    temp = full.iloc[i]['tokens']\n",
    "    for item in temp:\n",
    "        if item['label'] is None and item['pos'] == 'PERSON':\n",
    "            res = classifier(item['token'], labels)\n",
    "            print(res['sequence'],' : ', res['scores'][0])\n",
    "            if (res['scores'][0] > threshold):\n",
    "                item['label'] = 'artist'\n",
    "                item['is_weak_label'] = True'''\n",
    "\n",
    "#full.to_json('./full-checkpoint.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training\n",
    "Spacy needs data in it's Doc() object form. In this section, we trim the DF to only strongly labeled examples and convert the existing dataframe into docs and write it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a special operations member that looks like colin farrell and brad pitt, in battle, covert military pants, military boots, greek mythology, oil reinassance painting by cornelis van poelenburgh and dosso dossi, ultra detailed, concept art, 8 k what \n",
      "[{'value': {'start': 168, 'end': 192, 'text': 'cornelis van poelenburgh', 'labels': ['Artist']}, 'id': '-PCrj-bI4Z', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'manual'}, {'value': {'start': 197, 'end': 208, 'text': 'dosso dossi', 'labels': ['Artist']}, 'id': 'y01Q-cujWT', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'manual'}]\n"
     ]
    }
   ],
   "source": [
    "trim = pd.read_json('./trim-df.json', orient='split')\n",
    "print(trim['prompt'][0])\n",
    "print(trim['gt_raw'][0]['annotations'])\n",
    "\n",
    "''''\n",
    "[(\"a special operations member that looks like colin farrell and brad pitt, in battle, covert military pants, military boots, greek mythology, oil reinassance painting by cornelis van poelenburgh and dosso dossi, ultra detailed, concept art, 8 k what\",[(168,182,artist),(197,208,artist)]) ...]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colin farrell\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [362], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m span \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[39mprint\u001b[39m(span)\n\u001b[0;32m---> 36\u001b[0m         \u001b[39mprint\u001b[39m(span\u001b[39m.\u001b[39;49mchar_span\u001b[39m.\u001b[39;49mlabel)\n\u001b[1;32m     37\u001b[0m         ents\u001b[39m.\u001b[39mappend(span)\n\u001b[1;32m     38\u001b[0m doc\u001b[39m.\u001b[39ments \u001b[39m=\u001b[39m ents\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to Docs for training\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "nlp = spacy.blank(\"en\")\n",
    "db = DocBin()\n",
    "\n",
    "'''\n",
    "training_data = [\n",
    "  (\"Tokyo Tower is 333m tall.\", [(0, 11, \"BUILDING\")]),\n",
    "]\n",
    "'''\n",
    "\n",
    "for text, annotations in training_data:\n",
    "    doc = nlp(text)\n",
    "    #print(doc)\n",
    "    ents = []\n",
    "    #print(annotations)\n",
    "    for start, end, label in annotations:\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        #print(span.text)\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "db.to_disk(\"./train.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an NER model\n",
    "Model training is managed via spacy config files (prompt_config.cfg) and the command line. See **training-pipeline-output.txt** for checkpoints, loss, and overall score.\n",
    "\n",
    "*Note: You'll notice that I didn't split datasources to train/test/valid. Due to lack of GT, I have decided to evaluate the model's performance on prompt data from the HuggingFace dataset. See eval notebook in the repo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78432f6f3f29575f54084a0f731ad3137b13602a47f5f61425d7f4341eae791"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
